import { NextRequest, NextResponse } from 'next/server'
import { pool } from '@/lib/postgresql-client'

// Direct PostgreSQL connection
// Using centralized PostgreSQL client

export async function GET(request: NextRequest) {
  try {
    const startTime = Date.now()
    const client = await pool.connect()
    
    try {
      // Comprehensive performance metrics collection
      const performanceMetrics: any = {
        timestamp: new Date().toISOString(),
        server: 'enterprise-postgresql',
        version: '3.0',
        response_generation_time: 0,
        optimizations: {
          caching: 'enabled',
          indexes: 'optimized',
          auth: 'jwt-secured',
          connection_pooling: 'active',
          query_optimization: 'enabled'
        }
      }

      // 1. PostgreSQL Version and Uptime
      const { rows: serverInfo } = await client.query(`
        SELECT 
          version() as version,
          current_setting('server_version') as server_version,
          pg_postmaster_start_time() as start_time,
          now() - pg_postmaster_start_time() as uptime,
          current_database() as database_name,
          current_setting('port') as port
      `)
      
      performanceMetrics.postgresql = {
        version: serverInfo[0].server_version,
        uptime: serverInfo[0].uptime,
        database: serverInfo[0].database_name,
        port: serverInfo[0].port,
        start_time: serverInfo[0].start_time
      }

      // 2. Connection Pool Performance
      performanceMetrics.connection_pool = {
        total_connections: pool.totalCount,
        idle_connections: pool.idleCount,
        waiting_connections: pool.waitingCount,
        max_connections: 20,
        health_status: pool.waitingCount === 0 ? 'optimal' : 'moderate'
      }

      // 3. Database Performance Metrics
      const { rows: dbPerformance } = await client.query(`
        SELECT 
          numbackends as active_connections,
          xact_commit as transactions_committed,
          xact_rollback as transactions_rolled_back,
          blks_read as disk_blocks_read,
          blks_hit as cache_blocks_hit,
          tup_returned as tuples_returned,
          tup_fetched as tuples_fetched,
          tup_inserted as tuples_inserted,
          tup_updated as tuples_updated,
          tup_deleted as tuples_deleted,
          conflicts as conflicts,
          temp_files as temp_files,
          temp_bytes as temp_bytes,
          deadlocks as deadlocks
        FROM pg_stat_database 
        WHERE datname = current_database()
      `)
      
      const hitRatio = dbPerformance[0].cache_blocks_hit / 
                      (dbPerformance[0].disk_blocks_read + dbPerformance[0].cache_blocks_hit) * 100
      
      performanceMetrics.database_performance = {
        cache_hit_ratio: `${hitRatio.toFixed(2)}%`,
        cache_efficiency: hitRatio > 95 ? 'excellent' : hitRatio > 90 ? 'good' : 'needs_improvement',
        active_connections: parseInt(dbPerformance[0].active_connections),
        transactions: {
          committed: parseInt(dbPerformance[0].transactions_committed),
          rolled_back: parseInt(dbPerformance[0].transactions_rolled_back),
          success_rate: `${(dbPerformance[0].transactions_committed / 
                          (dbPerformance[0].transactions_committed + dbPerformance[0].transactions_rolled_back) * 100).toFixed(2)}%`
        },
        data_operations: {
          tuples_returned: parseInt(dbPerformance[0].tuples_returned),
          tuples_fetched: parseInt(dbPerformance[0].tuples_fetched),
          tuples_inserted: parseInt(dbPerformance[0].tuples_inserted),
          tuples_updated: parseInt(dbPerformance[0].tuples_updated),
          tuples_deleted: parseInt(dbPerformance[0].tuples_deleted)
        },
        system_health: {
          conflicts: parseInt(dbPerformance[0].conflicts),
          deadlocks: parseInt(dbPerformance[0].deadlocks),
          temp_files: parseInt(dbPerformance[0].temp_files),
          temp_usage: dbPerformance[0].temp_bytes
        }
      }

      // 4. Table Performance Analysis
      const { rows: tableStats } = await client.query(`
        SELECT 
          schemaname,
          tablename,
          n_tup_ins as inserts,
          n_tup_upd as updates,
          n_tup_del as deletes,
          n_live_tup as live_tuples,
          n_dead_tup as dead_tuples,
          last_vacuum,
          last_autovacuum,
          last_analyze,
          last_autoanalyze,
          seq_scan as sequential_scans,
          seq_tup_read as sequential_tuples_read,
          idx_scan as index_scans,
          idx_tup_fetch as index_tuples_fetched
        FROM pg_stat_user_tables 
        WHERE tablename IN ('employees', 'quotations', 'leads', 'tasks', 'notifications', 'companies')
        ORDER BY n_live_tup DESC
      `)
      
      performanceMetrics.table_performance = tableStats.map(table => ({
        table: table.tablename,
        live_tuples: parseInt(table.live_tuples),
        dead_tuples: parseInt(table.dead_tuples),
        maintenance_ratio: table.dead_tuples / (table.live_tuples + 1),
        scan_efficiency: table.index_scans / (table.sequential_scans + table.index_scans + 1),
        last_maintenance: table.last_autovacuum || table.last_vacuum,
        performance_score: table.index_scans > table.sequential_scans ? 'optimal' : 'needs_indexing'
      }))

      // 5. Index Performance
      const { rows: indexStats } = await client.query(`
        SELECT 
          schemaname,
          tablename,
          indexname,
          idx_tup_read as index_reads,
          idx_tup_fetch as index_fetches,
          idx_scan as index_scans
        FROM pg_stat_user_indexes 
        WHERE schemaname = 'public'
        ORDER BY idx_scan DESC
        LIMIT 10
      `)
      
      performanceMetrics.index_performance = {
        top_used_indexes: indexStats.map(idx => ({
          table: idx.tablename,
          index: idx.indexname,
          scans: parseInt(idx.index_scans),
          reads: parseInt(idx.index_reads),
          fetches: parseInt(idx.index_fetches),
          efficiency: idx.index_fetches / (idx.index_reads + 1)
        })),
        total_indexes_monitored: indexStats.length
      }

      // 6. Query Performance Timing
      const queryTime = Date.now() - startTime
      performanceMetrics.response_generation_time = `${queryTime}ms`
      performanceMetrics.query_performance = {
        metrics_collection_time: `${queryTime}ms`,
        performance_grade: queryTime < 100 ? 'A+' : queryTime < 200 ? 'A' : queryTime < 300 ? 'B' : 'C',
        optimization_status: queryTime < 100 ? 'optimal' : 'acceptable'
      }

      // 7. Memory and Resource Usage
      const { rows: memoryStats } = await client.query(`
        SELECT 
          setting as shared_buffers,
          unit
        FROM pg_settings 
        WHERE name = 'shared_buffers'
        UNION ALL
        SELECT 
          setting as work_mem,
          unit
        FROM pg_settings 
        WHERE name = 'work_mem'
      `)
      
      performanceMetrics.memory_configuration = memoryStats.reduce((acc, stat) => {
        const key = stat.shared_buffers ? 'shared_buffers' : 'work_mem'
        acc[key] = `${stat.shared_buffers || stat.work_mem}${stat.unit}`
        return acc
      }, {} as any)

      // 8. Business Data Performance
      const { rows: businessMetrics } = await client.query(`
        SELECT 
          (SELECT COUNT(*) FROM employees WHERE status = 'active') as active_employees,
          (SELECT COUNT(*) FROM quotations WHERE created_at >= CURRENT_DATE - INTERVAL '30 days') as recent_quotations,
          (SELECT COUNT(*) FROM leads WHERE created_at >= CURRENT_DATE - INTERVAL '7 days') as recent_leads,
          (SELECT COUNT(*) FROM tasks WHERE status = 'pending') as pending_tasks,
          (SELECT COUNT(*) FROM notifications WHERE is_read = false) as unread_notifications
      `)
      
      performanceMetrics.business_data_performance = {
        active_employees: parseInt(businessMetrics[0].active_employees),
        recent_quotations_30d: parseInt(businessMetrics[0].recent_quotations),
        recent_leads_7d: parseInt(businessMetrics[0].recent_leads),
        pending_tasks: parseInt(businessMetrics[0].pending_tasks),
        unread_notifications: parseInt(businessMetrics[0].unread_notifications),
        data_velocity: 'real-time',
        data_consistency: 'ACID-compliant'
      }

      // 9. System Recommendations
      const recommendations = []
      if (hitRatio < 90) recommendations.push('Consider increasing shared_buffers for better cache performance')
      if (pool.waitingCount > 0) recommendations.push('Monitor connection pool usage - consider increasing pool size')
      if (queryTime > 200) recommendations.push('Query performance could be improved with additional indexing')
      if (performanceMetrics.table_performance.some((t: any) => t.maintenance_ratio > 0.1)) {
        recommendations.push('Some tables have high dead tuple ratio - consider manual VACUUM')
      }
      if (recommendations.length === 0) recommendations.push('All performance metrics are optimal! ðŸš€')
      
      performanceMetrics.recommendations = recommendations
      performanceMetrics.overall_health = {
        database: hitRatio > 90 ? 'healthy' : 'needs_attention',
        connections: pool.waitingCount === 0 ? 'healthy' : 'monitor',
        queries: queryTime < 200 ? 'healthy' : 'optimize',
        overall_grade: hitRatio > 90 && queryTime < 200 && pool.waitingCount === 0 ? 'A+' : 'B+'
      }

      return NextResponse.json({
        success: true,
        performance_metrics: performanceMetrics,
        summary: {
          database_health: performanceMetrics.overall_health.overall_grade,
          response_time: `${queryTime}ms`,
          cache_efficiency: `${hitRatio.toFixed(1)}%`,
          active_connections: performanceMetrics.connection_pool.total_connections,
          total_metrics_collected: 8
        },
        metadata: {
          source: 'PostgreSQL Performance Monitor',
          collection_timestamp: new Date().toISOString(),
          monitoring_version: '3.0',
          features: [
            'Real-time PostgreSQL Metrics',
            'Connection Pool Monitoring',
            'Query Performance Analysis',
            'Index Usage Statistics',
            'Business Data Performance',
            'Memory Configuration Analysis',
            'Automated Recommendations'
          ]
        }
      })

    } finally {
      client.release()
    }

  } catch (error: any) {
    console.error('âŒ Performance metrics collection failed:', error)
    
    return NextResponse.json({
      success: false,
      error: 'Performance metrics collection failed',
      details: {
        message: error.message || String(error),
        code: error.code,
        detail: error.detail,
        hint: error.hint
      },
      fallback_metrics: {
        timestamp: new Date().toISOString(),
        server: 'performance-monitor-error',
        version: '3.0',
        status: 'error'
      },
      metadata: {
        source: 'PostgreSQL Performance Monitor',
        error_timestamp: new Date().toISOString()
      }
    }, { status: 500 })
  }
}